# ğŸ§  AI Agent Prototype - (Loan Assistant)

An AI-powered **loan assistance backend** built with **FastAPI**, **LangChain**, **FAISS**, and **OpenAI embeddings**. This service ingests internal documents, builds a persistent vector store, and exposes an API that can answer user questions using Retrieval-Augmented Generation (RAG).

The project is containerized with **Docker** and designed so embeddings are computed **once** and reused across restarts.

---

## ğŸš€ High-Level Architecture

```
User Request
    â†“
FastAPI API (/query)
    â†“
Retriever (FAISS Vector Store)
    â†“
Relevant Documents
    â†“
LLM (OpenAI)
    â†“
Final Answer
```

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ main.py          # FastAPI entrypoint
â”‚       â”œâ”€â”€ retriever.py     # Document loading + FAISS logic
â”‚       â”œâ”€â”€ chains.py        # RAG / QA chain logic
â”‚       â””â”€â”€ config.py        # App configuration
â”‚
â”œâ”€â”€ docs/                    # Source knowledge documents (.txt, .md)
â”‚   â”œâ”€â”€ loan_policy.md
â”‚   â””â”€â”€ faq.txt
â”‚
â”œâ”€â”€ vectorstore/
â”‚   â””â”€â”€ faiss/               # Persisted FAISS index (generated)
â”‚       â”œâ”€â”€ index.faiss
â”‚       â””â”€â”€ index.pkl
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## ğŸ§© How the App Works (Step-by-Step)

### Step 0 â€“ Startup Initialization
When the FastAPI app starts:

1. The **Retriever** is initialized
2. It checks whether a persisted FAISS index exists
3. If it exists â†’ load it from disk
4. If not â†’ load documents â†’ create embeddings â†’ build FAISS â†’ save it

This guarantees embeddings run **only once**.

---

### Step 1 â€“ Document Ingestion

Documents are loaded from:
```
/app/docs
```

Supported formats:
- `.txt`
- `.md`

Each document is:
- Read from disk
- Converted into LangChain `Document` objects
- Split into chunks (if configured)

---

### Step 2 â€“ Embedding & Vector Store (One-Time)

```python
FAISS.from_documents(docs, embeddings)
```

- Uses **OpenAI Embeddings** (`text-embedding-3-small`)
- Converts text â†’ vectors
- Stores them in FAISS

Persisted via:
```python
vectorstore.save_local("vectorstore/faiss")
```

---

### Step 3 â€“ Query Flow (Runtime)

1. User sends a question to the API
2. Question is embedded
3. FAISS performs similarity search
4. Top-K documents are retrieved
5. Documents + question are sent to the LLM
6. Model generates a grounded response

---

## ğŸ³ Running with Docker

### 1ï¸âƒ£ Build the Image

```bash
docker build -t ai-loan-assistant .
```

---

### 2ï¸âƒ£ Run the Container (With Persistence)

```bash
docker run \
  -p 8000:8000 \
  -v $(pwd)/vectorstore:/app/vectorstore \
  --env-file .env \
  ai-loan-assistant
```

ğŸ“Œ The volume mount ensures embeddings **do not rerun** on restart.

---

### 3ï¸âƒ£ Environment Variables (`.env`)

```env
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxx
```

---

## ğŸ” Testing the App

### Health Check

```bash
curl http://localhost:8000/health
```

### Query Endpoint

```bash
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"question": "What loan products do we offer?"}'
```

---

## ğŸ’¾ FAISS Persistence Details

FAISS data is stored at:
```
/app/vectorstore/faiss/
```

Files:
- `index.faiss` â†’ Vector index
- `index.pkl` â†’ Metadata + documents

If these files exist, embeddings **will not run again**.

---

## âš ï¸ Common Issues

### No Documents Loaded

Log:
```
No documents found. Skipping index build.
```

Fix:
- Ensure `.txt` or `.md` files exist in `/docs`
- Confirm Docker copied or mounted the directory

---

### OpenAI Rate Limit / Quota Error

```
openai.RateLimitError: insufficient_quota
```

Fix:
- Verify billing is enabled
- Ensure embeddings are not re-running

---

## ğŸ” Security Notes

- Never commit `.env` files
- API keys are injected at runtime
- Vectorstore files contain embeddings, not raw secrets

---

## ğŸ›£ï¸ Roadmap

- [ ] Add document hashing to auto-rebuild index only when docs change
- [ ] Add streaming responses
- [ ] Support PDF ingestion
- [ ] Add authentication
- [ ] Swap to local embeddings for zero cost

---

## ğŸ¤ Contributing

Pull requests welcome. Please:
- Follow existing structure
- Add logging for startup steps
- Keep embeddings deterministic

---

## ğŸ“œ License

MIT License

